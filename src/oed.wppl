var pam = function(arr,f) {
    return map(f,arr)
};

var score = function(erp, x) {
    // for backwards compatibility with webppl < 0.7
    //return Math.max(erp.score(null, x), erp.score(x));
    // NB: ^ isn't bullet proof
    erp.score(x)
}

var exp = function(x) {
    return Math.exp(x);
}

var expectation = function(erp) {
    sum(map(function(state) { return exp(score(erp, state)) * state },
            erp.support()))
}

var variance = function(erp) {
    var mean = expectation(erp)

    sum(map(function(state) { return exp(score(erp, state)) * (state - mean)*(state-mean) },
            erp.support()))
}

var Model = function(name, thunk) {
    Object.defineProperty(thunk, 'name', {value: name})
    return thunk;
};

// Given a name: thunk object, Models will name each function
var Models = function(obj) {
    return map(function(key) {
        return Model(key, obj[key]);
    }, Object.keys(obj));
};

// TODO: using this on priors and posteriors Just Works when the supports
// are {name: ..., func: ...} objects, which is a little surprising
// figure out why this works
var KL = function(P, Q) {
    var statesP = P.support();
    var statesQ = Q.support();

    // TODO: assert that states1 = states2
    return sum(map(
        function(state) {
            var scoreP = score(P, state), scoreQ = score(Q, state);
            var probP = exp(scoreP);
            // P(i) * log[ P(i) / Q(i) ] =  P(i) * [log(P(i) - log(Q(i)))]
            return probP * (scoreP - scoreQ);
        },
        statesP));
}

// compute actual information gain
var AIG = function(args) {
    var M = args.M,
        x = args.x,
        y = args.y;

    var infer = args.infer || {};
    var inferM1 = infer.M1 || Enumerate;
    var inferM2 = infer.M2 || Enumerate;
    var mPrior = inferM1(function() {
        var m = M();
        return {name: m.name, func: m};
    });

    var mPosterior = inferM2(function() {
        var mData = sample(mPrior), mName = mData.name, mFunc = mData.func;
        var LL = mFunc(x,y);
        factor(LL);
        return mData;
    });

    return KL(mPosterior, mPrior);
}


// notes: doesn't seem to work with incrementalMH right now
var EIG = function(args) {
    var M = args.M, X = args.X, Y = args.Y;
    // example: could use MH for M1 but then enumerate for M2
    var infer = args.infer || {},
        inferX = infer.X || Enumerate,
        inferY = infer.Y || Enumerate,
        inferM1 = infer.M1 || Enumerate,
        inferM2 = infer.M2 || Enumerate,
        mFuncs = args.mFuncs,
        usePredictiveY = !!args.usePredictiveY;

    var mPrior = inferM1(function() {
        var m = M();
        return {name: m.name, func: m}
    });

    inferX(function() {
        var x = X();
        // wrt the above distribution on responses, what is the posterior distribution on models?
        var KLDist = inferY(function() {
            var y = Y();
            if (args.usePredictiveY) {
                var _m = sample(mPrior), mName = _m.name, mFunc = _m.func;
                var scoreY = mFunc(x,y);
                factor(scoreY);
            }
            var mPosterior = inferM2(function() {
                var _m2 = sample(mPrior), m2Name = _m2.name, m2Func = _m2.func;
                var ll = m2Func(x,y);
                factor(ll);
                return _m2;
            });
            var kl = KL(mPosterior, mPrior);
            return kl;
        });

        // is there a way of getting confidence intervals around eig?
        var EIG = expectation(KLDist);
        factor(EIG);
        // var VIG = variance(KLDist);
        // return {x: x, EIG: EIG, VIG: VIG}
        return {x: x, EIG: EIG}
    })
}

var OED = EIG;
