var pam = function(arr,f) {
    return map(f,arr)
};

var score = function(erp, x) {
    // for backwards compatibility with webppl < 0.7
    //return Math.max(erp.score(null, x), erp.score(x));
    // NB: ^ isn't bullet proof
    erp.score(x)
}

var exp = function(x) {
    return Math.exp(x);
}

// If "prop" is specified, then the expectation will be computed with that
// property of each state. Otherwise, the state itself will be used, assuming
// that the distribution states are numeric.
var expectation = function(erp, prop) {
    return sum(map(function(state) {
        return exp(score(erp, state)) * ((!!prop) ? state[prop] : state);
    }, erp.support()));
};

var logsumexpectation = function(erp, prop) {
    return util.logsumexp(map(function(state) {
        return score(erp, state) + ((!!prop) ? state[prop] : state);
    }, erp.support()));
};

var variance = function(erp) {
    var mean = expectation(erp)

    sum(map(function(state) { return exp(score(erp, state)) * (state - mean)*(state-mean) },
            erp.support()))
}

var Model = function(name, f) {
    Object.defineProperty(f, 'name', {value: name})
    return f;
};

// Given a name: thunk object, Models will name each function
var Models = function(obj) {
    return map(function(key) {
        return Model(key, obj[key]);
    }, Object.keys(obj));
};

var getBestExpt = function(expts) {
    return reduce(function(expt, currMax) {
        return (expt.EIG > currMax.EIG) ? expt : currMax;
    }, {x: null, EIG: -Infinity}, expts);
};

// TODO: using this on priors and posteriors Just Works when the supports
// are {name: ..., func: ...} objects, which is a little surprising
// figure out why this works
// If pProp is specified, then Q is scored with that property of P support
// elements (necessary if model posterior contains extra information)
var KL = function(P, Q, pProp) {
    var statesP = P.support();
    var statesQ = Q.support();

    // TODO: assert that states1 = states2
    return sum(map(
        function(state) {
            var scoreP = score(P, state);
            var scoreQ = score(Q, ((!!pProp) ? state[pProp] : state));
            var probP = exp(scoreP);
            // P(i) * log[ P(i) / Q(i) ] =  P(i) * [log(P(i) - log(Q(i)))]
            // Let \lim_{x \to 0} x \log(x) = 0.
            // Otherwise, 0 * -Infinity = NaN.
            if (probP === 0) {
                return 0;
            }
            return probP * (scoreP - scoreQ);
        },
        statesP));
}

var updatePosterior = function(args) {
    var M = args.M,
        x = args.x,
        y = args.y;

    var infer = args.infer || {},
        inferM1 = infer.M1 || Enumerate,
        inferM2 = infer.M2 || Enumerate;

    var mPrior = args.mPrior || inferM1(function() {
        var m = M();
        return {name: m.name, func: m};
    });

    var mPosterior = inferM2(function() {
        var mData = sample(mPrior), mName = mData.name, mFunc = mData.func;
        var LL = mFunc(x,y);
        factor(LL);
        return mData;
    });

    return {
        mPosterior: mPosterior,
        AIG: KL(mPosterior, mPrior)
    };
};

// compute actual information gain
var AIG = function(args) {
    return updatePosterior(args).AIG;
};

// notes: doesn't seem to work with incrementalMH right now
var EIG = function(args) {
    var M = args.M, X = args.X, Y = args.Y;
    // example: could use MH for M1 but then enumerate for M2
    var infer = args.infer || {},
        inferX = infer.X || Enumerate,
        inferY = infer.Y || Enumerate,
        inferM1 = infer.M1 || Enumerate,
        inferM2 = infer.M2 || Enumerate,
        mFuncs = args.mFuncs,
        usePredictiveY = !!args.usePredictiveY,
        returnKL = !!args.returnKL;

    var cache = args.cache || {},
        doCaching = !_.isEmpty(cache);

    // Retrieve from cache if possible, otherwise fall back to model function.
    var retrieveCache = function(mName, mFunc, x, y) {
        return (
            cache[mName] && cache[mName][x.name] && cache[mName][x.name][y.name]
        ) || (
            mFunc(x, y)
        );
    };

    // Construct mPrior either 1) if it's provided in args, or 2) from the
    // model sample function. Note that args.mPrior overrides args.M if both
    // are present
    var mPrior = args.mPrior || inferM1(function() {
        var m = M();
        return {name: m.name, func: m};
    });

    inferX(function() {
        var x = X();
        // wrt the above distribution on responses, what is the posterior distribution on models?
        var KLDist = inferY(function() {
            var y = Y(x);

            var mPosterior = inferM2(function() {
                var _m = sample(mPrior), mName = _m.name, mFunc = _m.func;
                var ll = (doCaching) ?
                    retrieveCache(mName, mFunc, x, y) :
                    mFunc(x, y);
                factor(ll);
                return {m: _m, ll: ll};
            });

            var kl = KL(mPosterior, mPrior, 'm');
            if (args.usePredictiveY) {
                factor(logsumexpectation(mPosterior, 'll'));
            }
            return {y: y, kl: kl};
        });

        // is there a way of getting confidence intervals around eig?
        var EIG = expectation(KLDist, 'kl');
        factor(EIG);
        // var VIG = variance(KLDist);
        // return {x: x, EIG: EIG, VIG: VIG}
        return (returnKL) ? {x: x, EIG: EIG, KLDist: KLDist} : {x: x, EIG: EIG}
    })
}

// Return a JSON object of the form
// {
//  modelName: {
//   x1: {
//    y1: score1,
//    y2: score2,
//    ...
//   },
//   ...
//  },
//  ...
// }
// where objects are stringifed as necessary, to enable hashing.
// This allows caching model scoring. Works only with Enumerate, otherwise the
// caching won't be very useful
var cacheScores = function(args) {
    var M = args.M, X = args.X, Y = args.Y;

    var mPrior = args.mPrior || Enumerate(function() {
        var m = M();
        return {name: m.name, func: m};
    });

    var ms = mPrior.support();
    var mNames = _.pluck(ms, 'name');

    // TODO: Have an option to specify experiment/response IDs, like model
    // names, which can result in more efficient encoding
    var xs = Enumerate(function() {
        var x = X();
        return {name: x.name, x: x};
    }).support();
    var xNames = _.pluck(xs, 'name');

    // Since ys depend on x, this needs to map xs to arrays of ys
    var ys = _.object(xNames, pam(xs, function(x) {
        return Enumerate(function() {
            var y = Y(x.x);
            return {name: y.name, y: y};
        }).support();
    }));
    var yNames = mapObject(function(x, ys) {
        return _.pluck(ys, 'name');
    }, ys);

    return _.object(mNames, pam(ms, function(m) {
        var mFunc = m.func;
        return _.object(xNames, pam(xs, function(x) {
            var xys = ys[x.name];
            var xyns = yNames[x.name];
            return _.object(xyns, pam(xys, function(y) {
                return mFunc(x.x, y.y);
            }));
        }));
    }));
};

var OED = EIG;
